# # """
# # Resources: 
# # Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., & Luo, P. (2021). 
# # SegFormer: Simple and efficient design for semantic segmentation with transformers. 
# # Advances in neural information processing systems, 34, 12077-12090.
# # https://huggingface.co/docs/transformers/v4.48.2/en/model_doc/segformer
# # https://github.com/NVlabs/SegFormer
# # """

run_name: "segformer_mit_b5-base_run"

data:
  # batch_size: 4
  # batch_size_eval: 4
  batch_size: 1
  batch_size_eval: 1

augmentation:
  train:
    RandomScale:
      scale_limit: [0, 1]
    RandomCrop:
      width: 1920
      height: 1080  
    HorizontalFlip:
      p: 0.5
    Normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  val:
    Normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  test:
    Normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
      
model:
  name: "segformer-mit-b5"

training:
  epochs: 1700
  # epochs: 5
  optimizer:
    type: torch.optim.AdamW
    # lr: 0.00006
    lr: 0.0006
    weight_decay: 0.01
  scheduler:
    type: torch.optim.lr_scheduler.PolynomialLR
    power: 1
    total_iters: 1700
  preprocessor: "segformer"
  eval: 
    sliding_window: False
    window: 1920
    stride: 1080
  loss:
    type: cross_entropy
    # weight: [0.3599, 1.6741, 0.8887, 1.6131, 0.2925, 1.1718]


